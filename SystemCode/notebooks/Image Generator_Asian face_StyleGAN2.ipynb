{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import tensorflow.keras.layers as L\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as img\n",
    "\n",
    "import os\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from stylegan2 import StyleGAN2\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tensorflow version: \", tf.version.VERSION)\n",
    "print(\"numpy version: \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Modify this block to create your data loader:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, image_size, batch_size, source_folder = 'E:\\\\test\\StyleGAN2\\\\data\\\\GeneralPeople\\\\'):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.dataset = source_folder\n",
    "        self.images = list(os.listdir(self.dataset))\n",
    "        print(\"Number of images in the dataset:\", len(self.images))\n",
    "        \n",
    "    def get_batch(self):\n",
    "        batch = np.zeros((self.batch_size, self.image_size, self.image_size, 3), dtype = np.float32)\n",
    "        for b in range(self.batch_size):\n",
    "            try:\n",
    "                l = np.random.randint(len(self.images))\n",
    "                im = img.open(self.dataset + self.images[l]).convert('RGB')\n",
    "                h, w = im.size\n",
    "                if h > 512:\n",
    "                    ww = 0\n",
    "                    hh = np.random.randint(h - 512)\n",
    "                elif w > 512:\n",
    "                    ww = np.random.randint(w - 512)\n",
    "                    hh = 0\n",
    "                else:\n",
    "                    ww, hh = 0, 0\n",
    "                if np.random.rand() > 0.5:\n",
    "                    im = im.transpose(method=img.FLIP_LEFT_RIGHT)\n",
    "                #im = im.crop((hh, ww, hh + 512, ww + 512))\n",
    "                im = im.resize((self.image_size, self.image_size))\n",
    "                im = np.array(im, dtype = np.float32)\n",
    "                batch[b, :, :, :] = im[None, :self.image_size, :self.image_size, :] / 255.0\n",
    "            except:\n",
    "                print(\"Could not open image:\", self.dataset + self.images[l])\n",
    "        return batch\n",
    "\n",
    "print(DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create an instance of StyleGan and give it your data loader:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = StyleGAN2(image_size = 256, batch_size = 4, lr = 1e-5)\n",
    "gan.data_loader = DataLoader(gan.image_size, gan.batch_size, source_folder = 'E:\\\\test\\StyleGAN2\\\\data\\\\GeneralPeople\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load pre-trained weights if you want:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.loadWeights(suffix = \"_generalpeopleface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ready to train!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.train(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gan.history['G'])\n",
    "plt.plot(gan.history['D'])\n",
    "plt.ylim([-1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gan.history['R1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gan.history['pl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.saveWeights(suffix = \"_generalpeopleface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gan.batch_size\n",
    "collage = np.zeros((256 * b, 256 * b, 3))\n",
    "for i in range(b):\n",
    "    data = np.clip(gan.generate().numpy(), 0, 1)\n",
    "    data = np.reshape(data, (256 * b, 256, 3))\n",
    "    collage[:, 256 * i: 256 * (i + 1), :] = data\n",
    "plt.figure(figsize = (18, 18))\n",
    "plt.imshow(collage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gan.generate().numpy()\n",
    "\n",
    "for i in img:\n",
    "    plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}